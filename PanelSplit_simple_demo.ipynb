{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PanelSplit Demo\n",
    "\n",
    "In this notebook I introduce PanelSplit, a cross validator for panel data.\n",
    "\n",
    "\n",
    "### What is a cross validator?\n",
    "\n",
    "- Check out the visualizations in the [0. CrossValidation Strategies](https://www.kaggle.com/code/tomwarrens/timeseriessplit-how-to-use-it/notebook#0.-CrossValidation-Strategies) section of this kaggle notebook to understand how a cross validator works. \n",
    "\n",
    "- The cross validator defines these folds (subsets of training data), and the train/test sets within each fold.\n",
    "\n",
    "- They are often used with [hyper-parameter optimizers](https://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers). The hyper-parameter optimizer takes these folds and a set of hyper-parameters, and iterates through different hyperparameter combinations, evaluating each one's performance using the cross-validator's defined folds to determine the optimal set of hyperparameters for the model.\n",
    "\n",
    "\n",
    "### How does time-series cross-validation work? Understanding [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)\n",
    "\n",
    "\n",
    "From the sklearn documentation:\n",
    "\n",
    ">TimeSeriesSplit is a time-series cross validator. It provides train/test indices to split time series data samples that are observed at fixed time intervals, in train/test sets.\n",
    ">\n",
    ">In each split, test indices must be higher than before, and thus shuffling in cross validator is inappropriate.\"\n",
    "\n",
    "Upon initialization, it takes the following parameters:\n",
    "\n",
    "- n_splits: Number of splits\n",
    "- gap: Number of samples to exclude from the end of each train set before the test set\n",
    "- test_size: Used to limit the size of the test set\n",
    "- max_train_size: Maximum size for a single training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample indices\n",
    "x = list(range(6))\n",
    "print(f'Sample indices:{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of TimeSeriesSplit\n",
    "tss = TimeSeriesSplit(n_splits=3, gap=1, test_size=1).split(x)\n",
    "print(f'TimeSeriesSplit.split() returns type {type(tss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling TimeSeriesSplit.split() produces a 'generator' object. Upon its first usage, a list of the indices are produced. You can read more about generators [here](https://realpython.com/introduction-to-python-generators/), but the main point is that it yields a list, where each element within the list is a fold, and each fold contains train indices and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(tss):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore with different parameters (gap, n_splits, test_size, max_train_size) to understand how they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a function to visualize how time series split works.\n",
    "def plot_time_series_splits(split_output):\n",
    "    split_output = list(split_output)\n",
    "    folds = len(split_output)\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(split_output):\n",
    "        ax.scatter(train_index, [i] * len(train_index), color='blue', marker='.', s=50)\n",
    "        ax.scatter(test_index, [i] * len(test_index), color='red', marker='.', s=50)\n",
    "\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Fold')\n",
    "    ax.set_title('TimeSeriesSplit Cross-Validation')\n",
    "    ax.set_yticks(range(folds))  # Set the number of ticks on y-axis\n",
    "    ax.set_yticklabels([f'{i}' for i in range(folds)])  # Set custom labels for y-axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(10))\n",
    "tss = list(TimeSeriesSplit(n_splits=3, gap=0, test_size=1, max_train_size=3).split(x))\n",
    "plot_time_series_splits(tss)\n",
    "print(tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately while TimeSeriesSplit is useful for univariate time-series, it cannot be applied to panel data. \n",
    "\n",
    "It needs to be adapted for usage when there are multiple entities.\n",
    "\n",
    "## PanelSplit\n",
    "\n",
    "PanelSplit works as follows:\n",
    "\n",
    "1. Create train and test indices for each fold by passing the period series to TimeSeriesSplit\n",
    "2. For the train and test sets of each fold, substitute the with the corresponding period values\n",
    "3. For each train and test periods of each fold, filter for the period values in the panel data's periods and return their indices. \n",
    "\n",
    "Here is what the cross validator looks like. Though the X, and y and groups arguments aren't used for split() and get_n_splits(), they are required  as arguments when using a hyper-parameter optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelSplit:\n",
    "    def __init__(self, unique_periods, train_periods, n_splits = 5, gap = None, test_size = None, max_train_size=None):\n",
    "        \"\"\"\n",
    "        A class for performing time series cross-validation with custom train/test splits based on unique periods.\n",
    "\n",
    "        Parameters:\n",
    "        - n_splits: Number of splits for TimeSeriesSplit\n",
    "        - gap: Gap between train and test sets in TimeSeriesSplit\n",
    "        - test_size: Size of the test set in TimeSeriesSplit\n",
    "        - unique_periods: Pandas DataFrame or Series containing unique periods\n",
    "        - train_periods: All available training periods\n",
    "        - max_train_size: Maximum size for a single training set.\n",
    "        \"\"\"\n",
    "        self.tss = TimeSeriesSplit(n_splits=n_splits, gap=gap, test_size=test_size, max_train_size = max_train_size)\n",
    "        indices = self.tss.split(unique_periods)\n",
    "        self.u_periods_cv = self.split_unique_periods(indices, unique_periods)\n",
    "        self.all_periods = train_periods\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    def split_unique_periods(self, indices, unique_periods):\n",
    "        \"\"\"\n",
    "        Split unique periods into train/test sets based on TimeSeriesSplit indices.\n",
    "\n",
    "        Parameters:\n",
    "        - indices: TimeSeriesSplit indices\n",
    "        - unique_periods: Pandas DataFrame or Series containing unique periods\n",
    "\n",
    "        Returns: List of tuples containing train and test periods\n",
    "        \"\"\"\n",
    "        u_periods_cv = []\n",
    "        for i, (train_index, test_index) in enumerate(indices):\n",
    "            unique_train_periods = unique_periods.iloc[train_index].values\n",
    "            unique_test_periods = unique_periods.iloc[test_index].values\n",
    "            u_periods_cv.append((unique_train_periods, unique_test_periods))\n",
    "        return u_periods_cv\n",
    "\n",
    "    def split(self, X = None, y = None, groups=None):\n",
    "        \"\"\"\n",
    "        Generate train/test indices based on unique periods.\n",
    "        \"\"\"\n",
    "        self.all_indices = []\n",
    "        \n",
    "        for i, (train_periods, test_periods) in enumerate(self.u_periods_cv):\n",
    "            train_indices = self.all_periods.loc[self.all_periods.isin(train_periods)].index\n",
    "            test_indices = self.all_periods.loc[self.all_periods.isin(test_periods)].index\n",
    "            self.all_indices.append((train_indices, test_indices))\n",
    "        \n",
    "        return self.all_indices\n",
    "   \n",
    "    def get_n_splits(self, X=None, y =None, groups=None):\n",
    "        \"\"\"\n",
    "        Returns: Number of splits\n",
    "        \"\"\"\n",
    "        return self.n_splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in the data, filtering for a short period (the first half of 2015).\n",
    "# We select two countries, Spain, France.\n",
    "# We also select a few columns including indices, target variable and 2 features.\n",
    "df = pd.read_csv('df_merged_light.csv'). \\\n",
    "    query('period < 201507 & period > 201412'). \\\n",
    "    query(\"isocode.isin(['ESP','FRA'])\") \\\n",
    "    [['isocode','period','ons_armedconf_12','pr_topic_0', 'past_bestpc_12']]. \\\n",
    "    reset_index(drop=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing PanelSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the unique period series\n",
    "unique_sorted_periods = pd.Series(df.period.unique()).sort_values()\n",
    "\n",
    "# initialize panel split\n",
    "panel_split = PanelSplit(n_splits = 3, gap=1, test_size=1, \n",
    "                         unique_periods=unique_sorted_periods, train_periods=df.period)\n",
    "\n",
    "print('Initalizing PanelSplit creates folds of periods. These are within self.u_periods_cv.')\n",
    "for i, (train_periods, test_periods) in enumerate(panel_split.u_periods_cv):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: periods={train_periods}\")\n",
    "    print(f\"  Test:  periods={test_periods}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split()\n",
    "\n",
    "After we have substituted the period values for the indices in the PanelSplit initialization, the split() function filters for observations in the panel data that \n",
    "match the folds of the u_periods_cv list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the features and target\n",
    "feature_cols = ['pr_topic_0', 'past_bestpc_12']; target_col = 'ons_armedconf_12'\n",
    "features = df[feature_cols]; target = df[target_col]\n",
    "\n",
    "panel_data_cv = PanelSplit(n_splits = 3, gap=1, test_size=1, unique_periods=unique_sorted_periods, train_periods=df.period). \\\n",
    "    split(features, target)\n",
    "\n",
    "print('The split function returns panel data indices.')\n",
    "print('First fold indices:')\n",
    "print(panel_data_cv[0])\n",
    "\n",
    "print('First fold train set:')\n",
    "display(df.loc[panel_data_cv[0][0]])\n",
    "\n",
    "print('First fold test set:')\n",
    "display(df.loc[panel_data_cv[0][1]])\n",
    "\n",
    "print('Second fold indices:')\n",
    "print(panel_data_cv[1])\n",
    "\n",
    "print('Second fold train set:')\n",
    "display(df.loc[panel_data_cv[1][0]])\n",
    "\n",
    "print('Second fold test set:')\n",
    "display(df.loc[panel_data_cv[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with PanelSplit\n",
    "\n",
    "Before doing hyperparameter tuning, I reset indices and drop NaN values with respect to both feature variables and the target. This usually saves me from indexing errors when working with PanelSplit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_merged_light.csv', engine='pyarrow'). \\\n",
    "    query('period < 201507 & period > 201412'). \\\n",
    "    query(\"isocode.isin(['ESP','FRA'])\") \\\n",
    "    [['isocode','period','ons_armedconf_12','pr_topic_0', 'past_bestpc_12']]. \\\n",
    "    reset_index(drop=True)\n",
    "\n",
    "feature_cols = ['pr_topic_0', 'past_bestpc_12']; target_col = 'ons_armedconf_12'\n",
    "\n",
    "df = df.dropna(subset=feature_cols + [target_col]).reset_index(drop=True)\n",
    "features = df[feature_cols]; target = df[target_col]\n",
    "unique_sorted_periods = pd.Series(df.period.unique()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV; from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "panel_split = PanelSplit(n_splits = 3, gap= 1, test_size= 1, unique_periods=unique_sorted_periods, train_periods=df.period)\n",
    "\n",
    "param_grid = {'max_depth': [2, 3]}\n",
    "\n",
    "param_search = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                            param_grid = param_grid,\n",
    "                            cv=panel_split,\n",
    "                            verbose = 3)\n",
    "\n",
    "param_search.fit(features, target)\n",
    "\n",
    "print(f'GridSearch results:')\n",
    "display(pd.DataFrame(param_search.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a more practical example, setting the gap to 12, working with all countries up to 2016, and including more feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data:\n",
    "df = pd.read_csv('df_merged_light.csv', engine='pyarrow').query('period < 201601')\n",
    "\n",
    "feature_cols = ['pr_topic_0', 'pr_topic_1', 'pr_topic_2', 'population','since_armedconf', 'past_bestpc_6', 'past_bestpc_12']; target_col = 'ons_armedconf_12'\n",
    "# dropping NaNs and resetting indices\n",
    "train = df.dropna(subset= feature_cols + [target_col]).reset_index(drop=True)\n",
    "\n",
    "features, target, train_periods = train[feature_cols], train[target_col], train.period\n",
    "\n",
    "# generate a unique sorted period series.\n",
    "unique_sorted_periods = pd.Series(train_periods.unique()).sort_values()\n",
    "\n",
    "panel_split = PanelSplit(n_splits = 3, gap= 12, test_size= 1, unique_periods=unique_sorted_periods, train_periods=train_periods)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 7],\n",
    "    'min_samples_leaf':[10,100]\n",
    "}\n",
    "\n",
    "param_search = GridSearchCV(RandomForestClassifier(), \n",
    "                                param_grid,\n",
    "                                scoring='roc_auc', \n",
    "                                cv=panel_split,\n",
    "                                n_jobs=-1,\n",
    "                                verbose = 1)\n",
    "param_search.fit(features, target)\n",
    "\n",
    "print('GridSearch results:')\n",
    "display(pd.DataFrame(param_search.cv_results_).sort_values('rank_test_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with PanelSplit\n",
    "Once we have determined the best parameters using a hyper-parameter optimzer, PanelSplit can also be used for generating predictions.\n",
    "\n",
    "In this case I create cross_val_predict to take a classifier and for each fold, train on the train indices and predict_proba on the test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(estimator, X, y, indices, cv):\n",
    "    \"\"\"\n",
    "    Perform cross-validated predictions using a given predictor model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    estimator : The machine learning model used for prediction.\n",
    "\n",
    "    X : pandas DataFrame\n",
    "        The input features for the predictor.\n",
    "\n",
    "    y : pandas Series\n",
    "        The target variable to be predicted.\n",
    "\n",
    "    indices : pandas DataFrame\n",
    "        Indices corresponding to the dataset.\n",
    "\n",
    "    cv : cross-validation generator\n",
    "        A cross-validation splitting strategy.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Concatenated DataFrame containing predictions made by the model during cross-validation.\n",
    "        It includes the original indices joined with the predicted values.\n",
    "\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for train_index, test_index in tqdm(cv.split(X, y)):\n",
    "        # first drop nas with respect to y_train\n",
    "        y_train = y.iloc[train_index].dropna()\n",
    "        # use y_train to filter for X_train\n",
    "        X_train = X.iloc[y_train.index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index] \n",
    "        \n",
    "        pred = indices.iloc[test_index].join(y_test)\n",
    "        \n",
    "        model = estimator.fit(X_train, y_train)\n",
    "        \n",
    "        pred[f'{y.name}_pred'] = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return pd.concat(predictions, axis=0)\n",
    "\n",
    "cross_val_predict(estimator= RandomForestClassifier(**param_search.best_params_), X = features, y = target, indices = train[['isocode','period']], cv = panel_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this cross_val_predict allows for target variables as NaN- you can drop NaN observations from the dataframe with respect to features, and then the function drops training observations where the target is NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data, dropping NaNs only with respect to the feature columns.\n",
    "train = pd.read_csv('df_merged_light.csv', engine='pyarrow'). \\\n",
    "    dropna(subset= feature_cols). \\\n",
    "        reset_index(drop=True)\n",
    "\n",
    "features, target, train_periods = train[feature_cols], train[target_col], train.period\n",
    "\n",
    "unique_sorted_periods = pd.Series(train_periods.unique()).sort_values()\n",
    "\n",
    "panel_split = PanelSplit(n_splits = 3, gap= 12, test_size= 1, \n",
    "                         unique_periods=unique_sorted_periods, train_periods=train_periods)\n",
    "\n",
    "cross_val_predict(RandomForestClassifier(**param_search.best_params_), features, target, train[['isocode','period']], panel_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing PanelSplit\n",
    "PanelSplit can be further customized. Here I add a function to plot and visualize the time-series splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelSplit:\n",
    "    def __init__(self, unique_periods, train_periods, n_splits = 5, gap = None, test_size = None, max_train_size=None, plot=False):\n",
    "        \"\"\"\n",
    "        A class for performing time series cross-validation with custom train/test splits based on unique periods.\n",
    "\n",
    "        Parameters:\n",
    "        - n_splits: Number of splits for TimeSeriesSplit\n",
    "        - gap: Gap between train and test sets in TimeSeriesSplit\n",
    "        - test_size: Size of the test set in TimeSeriesSplit\n",
    "        - unique_periods: Pandas DataFrame or Series containing unique periods\n",
    "        - train_periods: All available training periods\n",
    "        - max_train_size: Maximum size for a single training set.\n",
    "        - plot: Flag to visualize time series splits\n",
    "        \"\"\"\n",
    "        self.tss = TimeSeriesSplit(n_splits=n_splits, gap=gap, test_size=test_size, max_train_size = max_train_size)\n",
    "        indices = self.tss.split(unique_periods)\n",
    "        self.u_periods_cv = self.split_unique_periods(indices, unique_periods)\n",
    "        self.all_periods = train_periods\n",
    "        self.n_splits = n_splits\n",
    "        if plot:\n",
    "            self.plot_time_series_splits(self.u_periods_cv)\n",
    "        \n",
    "    def split_unique_periods(self, indices, unique_periods):\n",
    "        \"\"\"\n",
    "        Split unique periods into train/test sets based on TimeSeriesSplit indices.\n",
    "\n",
    "        Parameters:\n",
    "        - indices: TimeSeriesSplit indices\n",
    "        - unique_periods: Pandas DataFrame or Series containing unique periods\n",
    "\n",
    "        Returns: List of tuples containing train and test periods\n",
    "        \"\"\"\n",
    "        u_periods_cv = []\n",
    "        for i, (train_index, test_index) in enumerate(indices):\n",
    "            unique_train_periods = unique_periods.iloc[train_index].values\n",
    "            unique_test_periods = unique_periods.iloc[test_index].values\n",
    "            u_periods_cv.append((unique_train_periods, unique_test_periods))\n",
    "        return u_periods_cv\n",
    "\n",
    "    def split(self, X = None, y = None, groups=None):\n",
    "        \"\"\"\n",
    "        Generate train/test indices based on unique periods.\n",
    "        \"\"\"\n",
    "        self.all_indices = []\n",
    "        \n",
    "        for i, (train_periods, test_periods) in enumerate(self.u_periods_cv):\n",
    "            train_indices = self.all_periods.loc[self.all_periods.isin(train_periods)].index\n",
    "            test_indices = self.all_periods.loc[self.all_periods.isin(test_periods)].index\n",
    "            self.all_indices.append((train_indices, test_indices))\n",
    "        \n",
    "        return self.all_indices\n",
    "   \n",
    "    def get_n_splits(self, X=None, y =None, groups=None):\n",
    "        \"\"\"\n",
    "        Returns: Number of splits\n",
    "        \"\"\"\n",
    "        return self.n_splits\n",
    "    \n",
    "    def plot_time_series_splits(self, split_output):\n",
    "        \"\"\"\n",
    "        Visualize time series splits using a scatter plot.\n",
    "\n",
    "        Parameters:\n",
    "        - split_output: Output of time series splits\n",
    "        \"\"\"\n",
    "        folds = len(split_output)\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        def int_to_dt(an_array):\n",
    "            return pd.to_datetime(an_array.astype(str), format='%Y%m')\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(split_output):\n",
    "            ax.scatter(int_to_dt(train_index), [i] * len(train_index), color='blue', marker='.', s=50)\n",
    "            ax.scatter(int_to_dt(test_index), [i] * len(test_index), color='red', marker='.', s=50)\n",
    "\n",
    "        ax.set_xlabel('Periods')\n",
    "        ax.set_ylabel('Folds')\n",
    "        ax.set_title('Cross-Validation Splits')\n",
    "        ax.grid(True)\n",
    "        ax.set_yticks(range(folds))  # Set the number of ticks on y-axis\n",
    "        ax.set_yticklabels([f'{i}' for i in range(folds)])  # Set custom labels for y-axi\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_split = PanelSplit(unique_sorted_periods, train_periods, n_splits=12, gap=3, test_size=1, plot=True, max_train_size=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, I add:\n",
    "- Return warnings about and omit one-class folds\n",
    "- Working with different 'updated' values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelSplit_updated:\n",
    "    def __init__(self, n_splits, gap, test_size, unique_periods, train_periods, train_updated, drop_one_class_folds=False, X=None, y=None, plot=False, return_warning=True):\n",
    "        \"\"\"\n",
    "        A class for performing time series cross-validation with custom train/test splits based on unique periods.\n",
    "\n",
    "        Parameters:\n",
    "        - n_splits: Number of splits for TimeSeriesSplit\n",
    "        - gap: Gap between train and test sets in TimeSeriesSplit\n",
    "        - test_size: Size of the test set in TimeSeriesSplit\n",
    "        - unique_periods: Pandas DataFrame or Series containing unique periods\n",
    "        - train_periods: All available training periods\n",
    "        - drop_one_class_folds: Flag to drop folds with only one class in the test set\n",
    "        - X: Input features\n",
    "        - y: Target variable\n",
    "        - plot: Flag to visualize time series splits\n",
    "        - return_warning: Flag to return warning regarding one-class folds in the test set\n",
    "        \"\"\"\n",
    "        self.tss = TimeSeriesSplit(n_splits=n_splits, gap=gap, test_size=test_size)\n",
    "        indices = self.tss.split(unique_periods)\n",
    "        self.u_periods_cv = self.split_unique_periods(indices, unique_periods)\n",
    "        self.all_periods = train_periods; self.return_warning = return_warning; self.drop_one_class_folds = drop_one_class_folds; self.train_updated = train_updated\n",
    "        self.n_splits = self.split(X, y, return_n_splits=True)\n",
    "        \n",
    "        if plot:\n",
    "            self.plot_time_series_splits(self.u_periods_cv)\n",
    "    \n",
    "    def split_unique_periods(self, indices, unique_periods):\n",
    "        \"\"\"\n",
    "        Split unique periods into train/test sets based on TimeSeriesSplit indices.\n",
    "\n",
    "        Parameters:\n",
    "        - indices: TimeSeriesSplit indices\n",
    "        - unique_periods: Pandas DataFrame or Series containing unique periods\n",
    "\n",
    "        Returns:\n",
    "        - List of tuples containing train and test periods\n",
    "        \"\"\"\n",
    "        u_periods_cv = []\n",
    "        for i, (train_index, test_index) in enumerate(indices):\n",
    "            unique_train_periods = unique_periods.iloc[train_index].values\n",
    "            unique_test_periods = unique_periods.iloc[test_index].values\n",
    "            u_periods_cv.append((unique_train_periods, unique_test_periods))\n",
    "        return u_periods_cv\n",
    "\n",
    "    def split(self, X, y, groups=None, return_n_splits=False):\n",
    "        \"\"\"\n",
    "        Generate train/test indices based on unique periods and drop folds if specified.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features\n",
    "        - y: Target variable\n",
    "        - groups: Group labels for the samples\n",
    "        - return_n_splits: Flag to return the number of splits\n",
    "\n",
    "        Returns:\n",
    "        - List of tuples containing train and test indices or number of splits\n",
    "        \"\"\"\n",
    "        self.all_indices = []\n",
    "\n",
    "        for i, (train_periods, test_periods) in enumerate(self.u_periods_cv):\n",
    "            max_period = test_periods.max() if test_periods.max() > 201001 else 201001\n",
    "            train_selection = (self.all_periods.isin(train_periods)  & (self.train_updated == max_period))\n",
    "            test_selection = (self.all_periods.isin(test_periods) & (self.train_updated == max_period))\n",
    "                \n",
    "            train_indices = X.loc[train_selection].index\n",
    "            test_indices = y.loc[test_selection].index\n",
    "            \n",
    "            append_indices = self.check_classes_in_test(y, test_indices, test_periods, i, return_n_splits)\n",
    "            if append_indices:\n",
    "                self.all_indices.append((train_indices, test_indices))\n",
    "\n",
    "        if return_n_splits:\n",
    "            return len(self.all_indices)\n",
    "        else:\n",
    "            return self.all_indices\n",
    "\n",
    "    def check_classes_in_test(self, y, test_indices, test_periods, i, return_n_splits):\n",
    "        \"\"\"\n",
    "        Check for the existence of a single class in the test set and handle accordingly.\n",
    "\n",
    "        Parameters:\n",
    "        - y: Target variable\n",
    "        - test_indices: Indices of the test set\n",
    "        - test_periods: Periods in the test set\n",
    "        - i: Fold index\n",
    "        - return_n_splits: Flag to return the number of splits\n",
    "        - return_warning: Flag to return warning regarding one-class folds in the test set\n",
    "\n",
    "        Returns:\n",
    "        - Boolean indicating whether to append indices or not\n",
    "        \"\"\"\n",
    "        # Check for existence of 1 in the test set\n",
    "        one_class = (y.loc[test_indices].sum() == 0)\n",
    "        if one_class and not self.drop_one_class_folds:\n",
    "            if return_n_splits:\n",
    "                if self.return_warning:\n",
    "                    print(f'''Warning: Fold {i} has no 1s in the test set, so it cannot compute ROC AUC.\n",
    "The period for this test set is {test_periods}''')\n",
    "            return True\n",
    "        elif one_class and self.drop_one_class_folds:\n",
    "            if return_n_splits:\n",
    "                print(f'Fold {i} has only one class in the test set (period {test_periods}). Omitting fold {i}.')\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    def plot_time_series_splits(self, split_output):\n",
    "        \"\"\"\n",
    "        Visualize time series splits using a scatter plot.\n",
    "\n",
    "        Parameters:\n",
    "        - split_output: Output of time series splits\n",
    "        \"\"\"\n",
    "        folds = len(split_output)\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        def int_to_dt(an_array):\n",
    "            return pd.to_datetime(an_array.astype(str), format='%Y%m')\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(split_output):\n",
    "            ax.scatter(int_to_dt(train_index), [i] * len(train_index), color='blue', marker='.', s=50)\n",
    "            ax.scatter(int_to_dt(test_index), [i] * len(test_index), color='red', marker='.', s=50)\n",
    "\n",
    "        ax.set_xlabel('Periods')\n",
    "        ax.set_ylabel('Folds')\n",
    "        ax.set_title('Cross-Validation Splits')\n",
    "        ax.grid(True)\n",
    "        ax.set_yticks(range(folds))  # Set the number of ticks on y-axis\n",
    "        ax.set_yticklabels([f'{i}' for i in range(folds)])  # Set custom labels for y-axi\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
